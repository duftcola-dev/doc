INDEX

1.0 # INSTALLATION
2.0 # BASIC COMMANDS
3.0 # CREATE A DOCKER IMAGE
	#Comments
	#Description
	#Author 
	#Date
4.0 # BUILD A DOCKER FILE :
5.0 # RUN A DOCKER IMAGE:
5.0 # SAVE/CREATE IMAGES IN DOCKER HUB 
6.0 # DOCKER VOLUMES 
7.0 # NETWORKS 
8.0 # DOCKER COMPOSE (For development)
9.0 # DOCKER COMPOSE (Production)
 10.0 # CREATE A .dockerignore


DOCKER USER MANUAL

1.0 # INSTALLATION

	**Ubuntu/linux installation** 
	** remove old versions**

	sudo apt-get remove docker docker-engine docker.io containerd runc

	sudo apt-get update
	sudo apt-get install \
    ca-certificates \
    curl \
    gnupg \
    lsb-release

	**Add docker official GPG key **

	sudo mkdir -p /etc/apt/keyrings
 	curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg

	**Setup the repository**

	echo \
	"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
	$(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

	**Install the docker engine**

	sudo apt-get update
 	sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin

	**Add tocker to the path**

	sudo groupadd docker
	sudo usermod -aG docker $USER
	newgrp docker 

	**Check the engine is working** 
	sudo docker run hello-world

	**install docker compose**

	sudo apt-get update
 	sudo apt-get install docker-compose-plugin

	**check versions**

	docker --version
	docker compose version


-----------------------------------------------------------------------------------------------


2.0 # BASIC COMMANDS

	
	docker ps  **current running container
	docker ps -a **previously run images
	docker ps -l **last container 
	docker ps -s **container size 
	docker images **see a list of the list availables
	docker system prune **clean /delete non used/stoped containers
	docker create <image_name> **creates a container .
	docker start <container id/container_name> **starts container
	docker run <image_name> **runs a docker image. Docker run executes docker create + docker start .
	docker stop **stop container . If the container does not stop run docker kill
	docker kill **force stop the container
	docker restart **restart contianer
	docker logs <container_id> ** just the cointainer logs
	docker tag <image_name> <new_tag>/<image_name>
	docker rmi <image_id> ** removes and image
	docker rm <container_id> ** removes container
	docker volume ls **show the volumes that currently exists in docker.
	docker container inpect <container_name> **Show detailed informaton about a container.
	docker pull <image_name>:<image_version> downloads a new image form dockerhub
	docker exec -it <container_id> <command> ** allows to launch command in docker containers
	docker exec -it <container_id> /bin/bash ** enables a console inside de container


----------------------------------------------------------------------------------	


3.0 # CREATE A DOCKER IMAGE

** Docker files are blueprints for creating images or "recipes".
** Docker files are just files named : Dockerfile.
** In order to build and image you need to create a base image.
** Usually the base image is an OS like linux / windows / mac
** Alpine is a very light linux based docker image.

	#Comments
	#Description
	#Author 
	#Date
	FROM <image_name>	
	ENV <set_enviroment_variables>  
	RUN <commands> 
	COPY <source> <destination>  
	EXPOSE <port_number> 
	ENTRYPOINT [commands]
	CMD ["run_command_for_image" , "/home/app/entry_point_file"] 

	**FROM <image_name> : Image to ve installed in your container. Checkout dockerhub for
							image names.

	**ENV <env_varialbes> : key value environment variables.
		- example :
					ENV MY_NAME="John Doe"
					ENV MY_DOG=Rex\ The\ Dog
					ENV MY_CAT=fluffy
	
	**RUN: runs commands inside your images like in any operative system.
	
	**COPY : Copy instruction copies the local files in your machine into a directory inside the container.
		- example :
			. /home/app  **Copies the local "." files of the host machine int /home/app inside the container
	
	**EXPOSE : expose a connection port to the current network.
		- example : 
				EXPOSE 9000

	**ENTRYPOINT : Specifies the executalbe the container will use. This the language the container
				   will use to run files inside. 
				   The default entrypoint is  /bin/sh 
				   However we ca specify others like  Python , Go or make 
		-example :
			ENTRYPOINT [python]
			ENTRYPOINT [make]
			ENTRYPOINT ["/bin/echo"]
			** CMD then will use this entry points to run commands like
			CMD [install] ---> if ENTRYPOINT ["make"] then CMD is actually running  
			make install

	**CMD :	Execution commands .This commands will you the compiler/executable 
			defined in ENTRYPOINT . If ENTRYPOINT is no defined then 
			it will use the default ENTRYPOINT /bin/sh . Notice these commands require ""

	Example : 

		FROM python:3.9.9-bullseye

		ENV MY_PASSWORD="jon_doe"

		WORKDIR /.

		COPY requirements.txt requirements.txt

		RUN pip install -r requirements.txt --upgrade pip

		COPY . .

		EXPOSE 5000
		
		ENTRYPOINT [ "python" ]

		CMD ["app_flask.py"]


---------------------------------------------------------------------------------------------	
	

4.0 # BUILD A DOCKER FILE :

	sintaxis:

		**All docker files must be called Dockerfile

			docker build <image_url_location>
			
			docker build .  **If the Dockerfile is the current folder

			docker build -t <image_name:version> <image_url_location>  **name and tag your image

	
	How to retag/tag a dockerfile :
	docker tag <image_name> <new_tag>/<image_name>


---------------------------------------------------------------------------------------------


5.0 # RUN A DOCKER IMAGE:

	sintaxis:

		docker run <parameters> image_name:tag

		example:

			docker run image_name ls 
			**will display the directories inside the image.

	<PARAMATERS>
		
		-d  **run in detach mode 
		-p <machine_port>:<container_port> **binding of the host machine port and container port 
		--name <custom_name> **adds a custom name to the container 
		--network <network_name> **Adds a custom network to the container.
									**if used --network host then the host machine network is used.  
		--dns **Sets a custom dns to the container
		--ip  **Sets an ipv4 to the container
		--restart **Define a restart poilicy.
			--restart=no 
			--restart=always 
			--restart=on-failure:number_of_max_tries
			--restart=unless-stopped
		--memory <number><unit> **Define the memory the container can use. By defaul it uses all 
								the memory of the host machine.
								--memory=<number><unit> **units can be b,k,m,g.Minimun is 4m
		--entrypoint **Specifies the images entry point (Check poinrt 3.0 CREATE A DOCKER IMAGE)
						--entrypoint /bin/bash python  **2 entrypoint defined
		-e **Set environment variables 
					-e "host=localhost" "port=300"  ...
		-v <path_to_volume_folder>:<path_to_volume> **Creates a volume for the mounted image.
				-v /home/mysql/data:/var/lib/mysql **It is recomended to use an apsolute path
												   

	example :
		docker run -d -p<host_port>:<container_port> --name <custom_name> --net <network_name> image_name
	 

---------------------------------------------------------------------------------------------


5.0 # SAVE/CREATE IMAGES IN DOCKER HUB 

	**Create a dockerhub account and repository 	
	**create custom images 
	** the image name and repository name must match 

	example :

		duftcola/my_alpine **repo name 
		duftcola/my_alpine:latest **localimage 

	**login into docke hub from your local console:

		docker login 

			> introduce docker hub user 
			> introduce docker hub password
		
		if acces is grante you can push your image:
			docker push user_name_name/image_name:tagname


---------------------------------------------------------------------------------------------


6.0 # DOCKER VOLUMES 

	** Volumes are storage systems in docker images .
	** Volumnes allow data persistency in docker images.

	** Volumes types :

		- Mounted volumes (bind mounts)  : A directory of the machines is copied into a contianer.
											- have a high performance.
											- the use the resources and structure of the host machine.
										
		- Named volumes (data volume) : A new directory is created within docker's inner memory storage.
											- easier to backup.
											- work both in linux and windows systems.
											- can be safely share among containers.
											- can be incrypted

		- Anonymous volumes : Are any volumne created automatically by the image when no mounted volumes	
							  are specified.

	** MOUNTED VOLUMES (BIND MOUNTS)

		** use the -v </files_path>:<volumne_path> to specify the location of the volume.
		** each database mounts its volume in a different way. Check dockerhub to see 
		   how each database mounts its volumes .
		** in the case of mysql is :/var/lib/mysql

		*** If the files arleady exists and you perform a volume creation 
		then all the files that exists in the target folder are coppied into the volume :
		
		example :
			-v <local_files_path>:<volume_path>

		example:

		**This is an image without a volume.Thefore an Anonymous/Orphan volume is create. 

		docker run -d --name mysql -e "MYSQL_ROOT_PASSWORD=root" mysql:latest

		example :	
		**This is an image with a mounted volume .
		**If there are no files in /home/ubuntu/mysql/ the mysql image creates them. 
		** If there are files in /home/ubuntu/mysql/ the files are just copied into /var/lib/mysql.

		docker run -d -v /home/ubuntu/mysql/data:/var/lib/mysql  --name mysql -e "MYSQL_ROOT_PASSWORD=root" mysql:latest


	** NAMED VOLUMES (DATA VOLUMES)

		** Name volumes do not need to be addressed to a folder like mounted volumes.
		** Named volumes are managed by docker itsef and do not exists within your local machine.
		** use :  docker volume ls **Show all the volumes that currently exists in docker.

		sintaxis :
			-v volume_name:volume_path

		example :
		
		docker run -d -v mysql_volume:/var/lib/mysql  --name mysql -e "MYSQL_ROOT_PASSWORD=root" mysql:latest

		**notice this volume path : /var/lib/mysql is exclusive of mysql database images.

	
	** Data volumes that are not being used appear as orphan volumes .
	** An orphan olume can be eliminated as :

		- docker volume ls 
		- docker volume rm <volume_id> 
		
			or 
		- docker volumen rm <volume_name> 

	** Eliminate all orphan volumes (including Name volumes)

		docker volume rm $(docker volume ls -f=dangling=true -q)

---------------------------------------------------------------------------------------------

7.0 # NETWORKS 

	**show default docker networks
	
	docker networks ls 

	**by default docker has the following networks with the following drivers

		**network_name:driver_name

		- bridge:bridge** Every contianer created is added to the bridge network
		- host:host   ** Host machine network . Connecting an image to this network grant access to internet
		- none:null

	**Networks with the bridge driver can connect with eachother.Bridge is a also eht driver by default.
	
	**Create your own network :

		docker network create --driver bridge my_bridge_network

		**use -->  docker netwok inspect <network_name>  in order to see the details of the network.

	**Add a container to the created network 

		docker run -d --name container_x --network my_bridge_network image_name

	**Connect a standalone container with a network to different network.

		docker network connect <network_name> <container_name>

---------------------------------------------------------------------------------------------

8.0 # DOCKER COMPOSE (For development)

** Docker compose is just a file to contain docker commands
** Docker compose automatically looks for .env files in the current directory when created 
** You can add the values of your .env file the docker-compose file using ${variable_name}
** You can also pass a .env file as argument --> docker-compose --env-file ./config/.env.dev up
** Use the -f flag to call docker compose from a different file --> docker compose -f /file_path/docker-compose.yaml up 
** Environment variables can also be set using the tag :

	environment:
		- VARIABLE1=1
		- VARIABLE1=2
		- VARIABLE1=3
	
	**Though this option is only recomended for testing/development since it exposes the variables


** Build you docker compose file with docker-compose up -d
** Stop you docker compose files with docker-compose down
** Use the tag -f to specify a path to the docker compose file : docker-compose -f <path/dev.yaml> up

sintaxis:

	version: '<version>'

	services:
		service_name:
			container_name: <container_name>
			image: <image_name>  **not compatible with build
			build:  **not compatible when suing the tag image
				context: <docker_file_path> ** use  . if in the saem folder
				dockerfile: <path_to_docker_file>  ** In case we want to build an image from our own Dockerfile
			user: <user_tag> **use root for full access
			volumes:
				- <host_machine_path>:<container_file_path>  **for mounted volumes only
				- data_volume_name:<container_file_path> 	**for data volumes only

			networks:
				- <network_name>
				- <network_name>
				- ${networ_name} **from a .env file
				- ports:
					- <host_machine_port>:<container_port>
					- <host_machine_port>:<container_port>
			restart: <restart_option> **always , on-failure , no, unless-stopped
			command : ["commands", "this", "particular images  requires"]

	networks:
		network_name:
			name: network_custom_name
			driver: driver_name      ** driver types : bridge , host ,local
			external: true **If the network already exists or was previously created set this option
	
	volumnes: **for data volumes_only
		data_volume_name:
			name: volume_id

	------------------------------
	example of using .env files  :
	------------------------------

	$ cat .env 

	TAG=v1.5 

	$ cat docker-compose.yml 

	version: '3'
	services :
		web :
			image: "webapp:${TAG}"	


	----------------------------------------------
	example of docker compose file for development	
	----------------------------------------------
		version: '3.1'

		services:

		db:
			image: postgres
			user : root
			restart: always
			ports:
				- 8080:8080
			environment:
			POSTGRES_PASSWORD: some_passwords_service
			
			networks:
				- network_name_for_thi
			volumes:
				- ./some_folder:/data/some_subfoolder
		adminer:
			image: adminer
			restart: always
			ports:
			- 8080:8080

**the tag user: root **gives you full access to your volumes,this is important to sae your volumes in git

Using the docker compose command : 

	docker-compose -f <file_in_app_folder.yaml> up ** This starts and creates the containers in the compose file
	docker-compose -f <file_in_app_folder.yaml> down ** Stops all containers in the compose file


--------------------------------------------------------------------------------------------------------------

9.0 # DOCKER COMPOSE (Production)

	**Docker compose files when used in production need to follow certain specifications.

		- No bind (monted volumes). All volumes need to be data volumes so noone can modify
		  the files bond to the container.
		- Binding to the ports of the host. If it is an EC2 machine then the machine host is 80
		- Restart policy set to "always"
		- Consider then defining a production file called docker-compose.production.yml with its own configuration file.
		- Production files will override the values in the docker-compose files to set to prodution.
		- You can use this technich for creating development and testing compose files 

		example :

			docker compose -f docker-compose.yml -f docker-compose.production.yml up -d

			**Here the "production file is overriding the values of the compose file in order 
			to pass it a prodution configuration .

		example : **This can be don fo testing and development files as well

			docker compose -f docker-compose.yml -f docker-compose.development.yml up -d

			docker compose -f docker-compose.yml -f docker-compose.test.yml up -d


-------------------------------------------------------------------------------------------


 10.0 # CREATE A .dockerignore

	A .dockerignore file is a file that allow us to spedify rules on wich files 
	should be copied and build during the image building process thus they wont be
	packed and uploaded to  docker server.

	** files specified wont by copied during COPY . .
	** files specified wont be included during the build process 

	example of a .dockerignore :

		venv/
		.coverage
		__pycache__
		**/__pycache__
		*.pyc

	**SINTAX :

		*/temp*  **exclude files/directories that start by temp
		temp?    **exclude files/direcoties that contain the word 'temp'
		**/*.pycache  **exclude all files that end with '.pycache'
		*.md   ** exclude files that en with .md
		!README.md **except this .md file

-------------------------------------------------------------------------------------------


11.0 CI/CD 

	**CI/CI aka continous integration / continous development is the techinique that allow us to continue
	adding features and testing our application.

		(develop_branch)	(develop_branch) (main branch)        (cloud)
		local_development ----> github -------> github---------> deployment
							(CI/CD develop)
								- test 
								- build 
								- deploy

		- new features are tested / added in development branches
		- when tests pass new features are merged to the branch main 
		- when new features are validated in the main branch then they are deployed to production server like 
			- EC2 (AWS)
			- Elastic beanstalk (AWS)
			- other clouds etc

	** With some images is necessary to use the option -e CI=True 
	when using your contianer for testing in order to exit after the test.

	example :

		docker run -e CI=true ...