DOCKER USER MANUAL

1.0 # INSTALLATION

	**Ubuntu/linux installation** 
	** remove old versions**

	sudo apt-get remove docker docker-engine docker.io containerd runc

	sudo apt-get update
	sudo apt-get install \
    ca-certificates \
    curl \
    gnupg \
    lsb-release

	**Add docker official GPG key **

	sudo mkdir -p /etc/apt/keyrings
 	curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg

	**Setup the repository**

	echo \
	"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
	$(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

	**Install the docker engine**

	sudo apt-get update
 	sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin

	**Add tocker to the path**

	sudo groupadd docker
	sudo usermod -aG docker $USER
	newgrp docker 

	**Check the engine is working** 
	sudo docker run hello-world

	**install docker compose**

	sudo apt-get update
 	sudo apt-get install docker-compose-plugin

	**check versions**

	docker --version
	docker compose version

-----------------------------------------------------------------------------------------------

2.0 # BASIC COMMANDS

	
	docker ps  **current running container
	docker ps -a **previously run images
	docker ps -l **last container 
	docker ps -s **container size 
	docker images **see a list of the list availables
	docker system prune **clean /delete non used/stoped containers
	docker create <image_name> **creates a container .
	docker start <container id/container_name> **starts container
	docker run <image_name> **runs a docker image. Docker run executes docker create + docker start .
	docker stop **stop container . If the container does not stop run docker kill
	docker kill **force stop the container
	docker restart **restart contianer
	docker logs <container_id> ** just the cointainer logs
	docker tag <image_name> <new_tag>/<image_name>
	docker rmi <image_id> ** removes and image
	docker rm <container_id> ** removes container
	docker pull <image_name>:<image_version> downloads a new image form dockerhub
	docker exec -it <container_id> <command> ** allows to launch command in docker containers
	docker exec -it <container_id> /bin/bash ** enables a console inside de container


----------------------------------------------------------------------------------	


3.0 # CREATE A DOCKER IMAGE

** Docker files are blueprints for creating images or "recipes".
** Docker files are just files named : Dockerfile.
** In order to build and image you need to create a base image.
** Usually the base image is an OS like linux / windows / mac
** Alpine is a very light linux based docker image.

	#Comments
	#Description
	#Author 
	#Date
	FROM <image_name>	
	ENV <set_enviroment_variables>  
	RUN <commands> 
	COPY <source> <destination>  
	EXPOSE <port_number> 
	ENTRYPOINT [commands]
	CMD ["run_command_for_image" , "/home/app/entry_point_file"] 

	**FROM <image_name> : Image to ve installed in your container. Checkout dockerhub for
							image names.

	**ENV <env_varialbes> : key value environment variables.
		- example :
					ENV MY_NAME="John Doe"
					ENV MY_DOG=Rex\ The\ Dog
					ENV MY_CAT=fluffy
	
	**RUN: runs commands inside your images like in any operative system.
	
	**COPY : Copy instruction copies the local files in your machine into a directory inside the container.
		- example :
			. /home/app  **Copies the local "." files of the host machine int /home/app inside the container
	
	**EXPOSE : expose a connection port to the current network.
		- example : 
				EXPOSE 9000

	**ENTRYPOINT : Specifies the executalbe the container will use. This the language the container
				   will use to run files inside. 
				   The default entrypoint is  /bin/sh 
				   However we ca specify others like  Python , Go or make 
		-example :
			ENTRYPOINT [python]
			ENTRYPOINT [make]
			ENTRYPOINT ["/bin/echo"]
			** CMD then will use this entry points to run commands like
			CMD [install] ---> if ENTRYPOINT ["make"] then CMD is actually running  
			make install

	**CMD :	Execution commands .This commands will you the compiler/executable 
			defined in ENTRYPOINT . If ENTRYPOINT is no defined then 
			it will use the default ENTRYPOINT /bin/sh . Notice these commands require ""

Example : 

    FROM python:3.9.9-bullseye

    WORKDIR /.

    COPY requirements.txt requirements.txt

    RUN pip install -r requirements.txt --upgrade pip

    COPY . .

    EXPOSE 5000
    
    ENTRYPOINT [ "python" ]

    CMD ["app_flask.py"]

---------------------------------------------------------------------------------------------	
	
4.0 # BUILD A DOCKER FILE :

	sintaxis:

		**All docker files must be called Dockerfile

			docker build <image_url_location>
			
			docker build .  **If the Dockerfile is the current folder

			docker build -t <image_name:version> <image_url_location>  **name and tag your image

	
	How to retag/tag a dockerfile :
	docker tag <image_name> <new_tag>/<image_name>


---------------------------------------------------------------------------------------------


5.0 # RUN A DOCKER IMAGE:

	sintaxis:

		docker run <parameters> image_name:tag

		example:

			docker run image_name ls 
			**will display the directories inside the image.

	<PARAMATERS>
		
		-d  **run in detach mode 
		-p <machine_port>:<container_port> **binding of the host machine port and container port 
		--name <custom_name> **adds a custom name to the container 
		--network <network_name> **Adds a custom network to the container.
									**if used --network host then the host machine network is used.  
		--dns **Sets a custom dns to the container
		--ip  **Sets an ipv4 to the container
		--restart **Define a restart poilicy.
			--restart=no 
			--restart=always 
			--restart=on-failure:number_of_max_tries
			--restart=unless-stopped
		--memory <number><unit> **Define the memory the container can use. By defaul it uses all 
								the memory of the host machine.
								--memory=<number><unit> **units can be b,k,m,g.Minimun is 4m
		--entrypoint **Specifies the images entry point (Check poinrt 3.0 CREATE A DOCKER IMAGE)
						--entrypoint /bin/bash python  **2 entrypoint defined
		-e **Set environment variables 
					-e "host=localhost" "port=300"  ...

	example :
		docker run -d -p<host_port>:<container_port> --name <custom_name> --net <network_name> image_name
	 

	 

---------------------------------------------------------------------------------------------

# Interact with the environment files of the container: 

	docker exec -it <container_id> /bin/bash

	or 

	docker exec -it <container_name> <console_command>

	example:

		-docker exec -it redis_service redis-cli 
	
	**once inside the contianer inv you can use bash commands as usual like pwd ,ls , cd etc
	**env prints the environment variables

---------------------------------------------------------------------------------------------

# Create containers network

How to connect container and create a network of containers :
Example ( connect a flask container with a database container)

	docker network ls **Check the newtworks generated by docker by default
	docker network create <network-name>

---------------------------------------------------------------------------------------------

# Creating docker compose using docker yaml

** Docker compose is just a file to contain docker commands
**When Creating a Docker compose file no it is no necessary to create a network since the docker compose file does
it for you.
Example of a .yaml file for Postgresql:


version: '3.1'

services:

  db:
    image: postgres
    user : root
    restart: always
    ports:
    	- 8080:8080
    environment:
      POSTGRES_PASSWORD: some_passwords_service
     
    networks:
        - network_name_for_thi
    volumes:
        - ./some_folder:/data/some_subfoolder
  adminer:
    image: adminer
    restart: always
    ports:
      - 8080:8080

**the tag user: root **gives you full access to your volumes,this is important to sae your volumes in git

Using the docker compose command : 

	docker-compose -f <file_in_app_folder.yaml> up ** This starts adn creates the containers in the compose file
	docker-compose -f <file_in_app_folder.yaml> down ** Stops all containers in the compose file

-------------------------------------------------------------------------------------------

# Data persistance with Docker volumes. 

** The main use of docker volumes is to have data persistance . That means all the infor in your container/s is copied into a local folder so it can be save every time the container/s are stoped and restarted.
So basically the path to a file/folder in our host machine is added to the container fro persintency .

There are 2 types of docker volumes :

	1) Host volume : the reference
	*During docker run command add the option -v <path_to_host_folder>:<path_to_container_folder> where data 		will stored . ** <path_to_host_folder>:<path_to_container_folder> should be the same.
	
	2) Volume defined in docker-compose
	volumes:
	    - <folder_name_for_volume>:/sub_folder

		or

		- .:/sub_folder  **in case you want to create the volumen in the current location
--------------------------------------------------------------------------------------------

# Create a .dockerignore file

	A .dockerignore file is a file that allow us to spedify rules on wich files 
	should be copied and build during the image building process thus they wont be
	packed and uploaded to  docker server.

	** files specified wont by copied during COPY . .
	** files specified wont be included during the build process 

	example of a .dockerignore :

		venv
		.coverage
		__pycache__
		**/__pycache__
		*.pyc

	**SINTAX :

		*/temp*  **exclude files/directories that start by temp
		temp?    **exclude files/direcoties that contain the word 'temp'
		**/*.pycache  **exclude all files that end with '.pycache'
		*.md   ** exclude files that en with .md
		!README.md **except this .md file

-------------------------------------------------------------------------------------------

# Debugging docker container

	Basic debbuging :

		docker logs <container_name>
		or 
		docker logs <container_id>
	
	

--------------------------------------------------------------------------------------------

# Creating a private repository for Docker in AWS ECR (elastic container registry)
	
	** ECR is a private docker repository
	** I has registry options
	** allows build and tag images
	
	1) Log in into AWS and search ECR 
	2) Create a repository AWS ECR
	3) Login from you local PC using the login command provided by AWS ECR 
	** You need to have AWS CLI installed and have credentials to do step 3)
	4) tag the created image with the tag provided by AWS ECR
	5 push image
	
Development server in AWS ECR 

	** update your .yaml compose file with the new created image
	
	
	version: '3.1'

	services:
	  my-app:             ** Your app is going to be pulled from AWS ECR so the aws tag is very important
	    image: <aws-image-tag>/app_name
	    ports:
	    	-3000:3000

	  db:  		** Notice the other images are still necessary since thy will be 
	    image: postgres	   pulled from docker hub as dependencies
	    restart: always
	    ports:
	    	- 8080:8080
	    environment:
	      POSTGRES_PASSWORD: some_password

	  adminer:
	    image: adminer
	    restart: always
	    ports:
	      - 8080:8080
	      
	      
	  ** to summarize , your app image is being pulled from AWS ECR while the other dependencies are pulled 		     from docker hub so it is very important to use the AWS-tags to the deployiment server can make the 
	     distinction between both.
	 	
	
